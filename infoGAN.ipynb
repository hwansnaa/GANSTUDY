{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "infoGAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPcp4WHppHDmqVL0dJvOZW3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwansnaa/InfoGAN/blob/main/infoGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "5WajrzL8H79Z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import time\n",
        "import random\n",
        "\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST"
      ],
      "metadata": {
        "id": "D9yW-ANxZMq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.tconv1 = nn.ConvTranspose2d(74, 1024, 1, 1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(1024)\n",
        "\n",
        "        self.tconv2 = nn.ConvTranspose2d(1024, 128, 7, 1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.tconv3 = nn.ConvTranspose2d(128, 64, 4, 2, padding=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.tconv4 = nn.ConvTranspose2d(64, 1, 4, 2, padding=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.tconv1(x)))\n",
        "        x = F.relu(self.bn2(self.tconv2(x)))\n",
        "        x = F.relu(self.bn3(self.tconv3(x)))\n",
        "\n",
        "        img = torch.sigmoid(self.tconv4(x))\n",
        "\n",
        "        return img\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 64, 4, 2, 1)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(64, 128, 4, 2, 1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(128, 1024, 7, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(1024)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(1024, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.conv1(x), 0.1, inplace=True)\n",
        "        x = F.leaky_relu(self.bn2(self.conv2(x)), 0.1, inplace=True)\n",
        "        output = F.leaky_relu(self.bn3(self.conv3(x)), 0.1, inplace=True)\n",
        "        probs = torch.sigmoid(self.conv4(output))\n",
        "\n",
        "        return probs, output\n",
        "\n",
        "class QHead(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1024, 128, 1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv_disc = nn.Conv2d(128, 10, 1)\n",
        "        self.conv_mu = nn.Conv2d(128, 2, 1)\n",
        "        self.conv_var = nn.Conv2d(128, 2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.bn1(self.conv1(x)), 0.1, inplace=True)\n",
        "\n",
        "        disc_logits = self.conv_disc(x).squeeze()\n",
        "\n",
        "        mu = self.conv_mu(x).squeeze()\n",
        "        var = torch.exp(self.conv_var(x).squeeze())\n",
        "\n",
        "        return disc_logits, mu, var"
      ],
      "metadata": {
        "id": "V-7AEgFCZ_qs"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'batch_size': 128,# Batch size.\n",
        "    'num_epochs': 100,# Number of epochs to train for.\n",
        "    'learning_rate': 2e-4,# Learning rate.\n",
        "    'beta1': 0.5,\n",
        "    'beta2': 0.999,\n",
        "    'save_epoch' : 25,# After how many epochs to save checkpoints and generate test output.\n",
        "    'dataset' : 'MNIST'\n",
        "}\n",
        "params['num_z'] = 62\n",
        "params['num_dis_c'] = 1\n",
        "params['dis_c_dim'] = 10\n",
        "params['num_con_c'] = 2"
      ],
      "metadata": {
        "id": "NLkX4cfslyeo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def noise_sample(n_dis_c, dis_c_dim, n_con_c, n_z, batch_size, device):\n",
        "    \"\"\"\n",
        "    Sample random noise vector for training.\n",
        "    INPUT\n",
        "    --------\n",
        "    n_dis_c : Number of discrete latent code.\n",
        "    dis_c_dim : Dimension of discrete latent code.\n",
        "    n_con_c : Number of continuous latent code.\n",
        "    n_z : Dimension of iicompressible noise.\n",
        "    batch_size : Batch Size\n",
        "    device : GPU/CPU\n",
        "    \"\"\"\n",
        "\n",
        "    z = torch.randn(batch_size, n_z, 1, 1, device=device)\n",
        "\n",
        "    idx = np.zeros((n_dis_c, batch_size))\n",
        "    if(n_dis_c != 0):\n",
        "        dis_c = torch.zeros(batch_size, n_dis_c, dis_c_dim, device=device)\n",
        "        \n",
        "        for i in range(n_dis_c):\n",
        "            idx[i] = np.random.randint(dis_c_dim, size=batch_size)\n",
        "            dis_c[torch.arange(0, batch_size), i, idx[i]] = 1.0\n",
        "\n",
        "        dis_c = dis_c.view(batch_size, -1, 1, 1)\n",
        "\n",
        "    if(n_con_c != 0):\n",
        "        # Random uniform between -1 and 1.\n",
        "        con_c = torch.rand(batch_size, n_con_c, 1, 1, device=device) * 2 - 1\n",
        "\n",
        "    noise = z\n",
        "    if(n_dis_c != 0):\n",
        "        noise = torch.cat((z, dis_c), dim=1)\n",
        "    if(n_con_c != 0):\n",
        "        noise = torch.cat((noise, con_c), dim=1)\n",
        "\n",
        "    return noise, idx"
      ],
      "metadata": {
        "id": "Z4nNMMx-thye"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InfoGAN:\n",
        "  def __init__(self, params):\n",
        "      self.params = params\n",
        "      self.netG = Generator()\n",
        "      self.netD = Discriminator()\n",
        "      self.netQ = QHead()\n",
        "      self.optimD = optim.Adam([{'params': self.netD.parameters()}], lr=params['learning_rate'], betas=(params['beta1'], params['beta2']))\n",
        "      self.optimG = optim.Adam([{'params': self.netG.parameters()}, {'params': self.netQ.parameters()}], lr=params['learning_rate'], betas=(params['beta1'], params['beta2']))\n",
        "\n",
        "      self.criterionD = nn.BCELoss()\n",
        "      self.criterionQ_dis = nn.CrossEntropyLoss()\n",
        "      self.criterionQ_con = nn.NLLLoss()\n",
        "      \n",
        "      self.device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
        "\n",
        "  def train(self, ds, epochs = 100):\n",
        "    self.netG = self.netG.to(self.device)\n",
        "    self.netD = self.netD.to(self.device)\n",
        "    self.netQ = self.netQ.to(self.device)\n",
        "    G_losses = []\n",
        "    D_losses = []\n",
        "    for epoch in range(epochs):\n",
        "      for i, (data, _) in enumerate(ds, 0):\n",
        "          # Get batch size\n",
        "          b_size = data.size(0)\n",
        "          # Transfer data tensor to GPU/CPU (device)\n",
        "          real_data = data.to(self.device)\n",
        "\n",
        "          # Updating discriminator and DHead\n",
        "          self.optimD.zero_grad()\n",
        "          # Real data\n",
        "          label = torch.full((b_size, ), 1, device=self.device, dtype=torch.float32)\n",
        "          probs_real, _ = self.netD(real_data)\n",
        "          loss_real = self.criterionD(probs_real.view(-1), label)\n",
        "          \n",
        "          loss_real.backward()\n",
        "\n",
        "          # Fake data\n",
        "          label.fill_(0)\n",
        "          noise, idx = noise_sample(self.params['num_dis_c'], self.params['dis_c_dim'], self.params['num_con_c'], self.params['num_z'], b_size, self.device)\n",
        "          fake_data = self.netG(noise)\n",
        "          probs_fake, output_fake = self.netD(fake_data.detach())\n",
        "          loss_fake = self.criterionD(probs_fake.view(-1), label)\n",
        "          # Calculate gradients.\n",
        "          loss_fake.backward()\n",
        "\n",
        "          # Net Loss for the discriminator\n",
        "          D_loss = loss_real + loss_fake\n",
        "          # Update parameters\n",
        "          self.optimD.step()\n",
        "\n",
        "          # Updating Generator and QHead\n",
        "          self.optimG.zero_grad()\n",
        "\n",
        "          # Fake data treated as real.\n",
        "          probs_fake, output_fake = self.netD(fake_data)\n",
        "          label.fill_(1)\n",
        "          gen_loss = self.criterionD(probs_fake.view(-1), label)\n",
        "\n",
        "          q_logits, q_mu, q_var = self.netQ(output_fake)\n",
        "          target = torch.LongTensor(idx).to(self.device)\n",
        "          # Calculating loss for discrete latent code.\n",
        "          dis_loss = 0\n",
        "          for j in range(self.params['num_dis_c']):\n",
        "              dis_loss += self.criterionQ_dis(q_logits[:, j*10 : j*10 + 10], target[j])\n",
        "\n",
        "          # Calculating loss for continuous latent code.\n",
        "          con_loss = 0\n",
        "          if (self.params['num_con_c'] != 0):\n",
        "              print(noise[:, self.params['num_z']+ self.params['num_dis_c']*self.params['dis_c_dim'] : ].view(-1, self.params['num_con_c']).shape)\n",
        "              print(q_mu.shape)\n",
        "              print(q_var.shape)\n",
        "              con_loss = self.criterionQ_con(noise[:, self.params['num_z']+ self.params['num_dis_c']*self.params['dis_c_dim'] : ].view(-1, self.params['num_con_c']), q_mu, q_var)*0.1\n",
        "\n",
        "          # Net loss for generator.\n",
        "          G_loss = gen_loss + dis_loss + con_loss\n",
        "          # Calculate gradients.\n",
        "          G_loss.backward()\n",
        "          # Update parameters.\n",
        "          self.optimG.step()\n",
        "\n",
        "          # Check progress of training.\n",
        "          if i != 0 and i%100 == 0:\n",
        "              print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f'\n",
        "                    % (epoch+1,self. params['num_epochs'], i, len(ds), \n",
        "                      D_loss.item(), G_loss.item()))\n",
        "\n",
        "          # Save the losses for plotting.\n",
        "          G_losses.append(G_loss.item())\n",
        "          D_losses.append(D_loss.item())"
      ],
      "metadata": {
        "id": "j6apZ4T0e4ty"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets"
      ],
      "metadata": {
        "id": "2ibD9hEne4je"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(28),\n",
        "    transforms.CenterCrop(28),\n",
        "    transforms.ToTensor()])\n",
        "datasets = dsets.MNIST('data/mnist/', train='train', download=True, transform = transform)\n",
        "dataloader = torch.utils.data.DataLoader(datasets, \n",
        "                                            batch_size=64, \n",
        "                                            shuffle=True)"
      ],
      "metadata": {
        "id": "pRTUe1v5e4bU"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "infoGAN = InfoGAN(params)\n",
        "infoGAN.train(dataloader, 100)"
      ],
      "metadata": {
        "id": "IJdwJAhhe4Sy",
        "outputId": "9320f567-e6df-4ba2-e99d-06523fac1cf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 2])\n",
            "torch.Size([64, 2])\n",
            "torch.Size([64, 2])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-8ab8f6775b77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minfoGAN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInfoGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minfoGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-59-4bd1cd63b1f6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, ds, epochs)\u001b[0m\n\u001b[1;32m     71\u001b[0m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m               \u001b[0mcon_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterionQ_con\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_z'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_dis_c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dis_c_dim'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_con_c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m           \u001b[0;31m# Net loss for generator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() takes 3 positional arguments but 4 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aSqsVLwse4I3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IQk2sS7Te3-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wk8er5Yse3vA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tv04AzaIe09j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}